
```{r}
library(tidyverse)
library(synapser)
library(readxl)
library(googlesheets4)

synLogin()

gs4_deauth()
```

## MAKE DICTIONARY

Get dataset

```{r}
teamds_clinical_data <- read_xlsx(synGet("syn53058587")$path)
```


In Excel, identify columns that should be numeric but aren't - list below:

- height
- weight
- bmi

For the above cols, replace NA value: "missing"
And convert to numeric

Then select all numeric columns and get ranges (min-max)

```{r}
teamds_clinical_data_converted <- teamds_clinical_data %>% 
  mutate(height = as.numeric(na_if(height, "missing")), 
         weight = as.numeric(na_if(weight, "missing")), 
         bmi = as.numeric(na_if(bmi, "missing")))

teamds_num_entries <- teamds_clinical_data_converted %>% 
  select(where(is.numeric))  %>% 
  broom::tidy(summary()) %>% 
  select(original_header = column, min, max) %>% 
  unite(min, max, col = "values", sep = "-")

```

Get unique values for character columns

```{r}
teamds_clin_entries <- teamds_clinical_data_converted %>% 
  select(where(is.character)) %>% 
  pivot_longer(cols = everything(),
               names_to = "original_header",
               values_to = "all_values") %>% 
  group_by(original_header) %>% 
  summarize(values = paste(unique(all_values), collapse = "; "))
```


Assemble dictionary

```{r}
teamds_all_entries <- bind_rows(teamds_num_entries, teamds_clin_entries)

teamds_dict <- tibble("original_header" = colnames(teamds_clinical_data),
       "working_header" = NA) %>% 
  left_join(teamds_all_entries)
```

Write out and paste into Google sheet 
(https://docs.google.com/spreadsheets/d/118amKSbrLRbmHrczFPhkLsxLKFu3GEr5goPMDvrlvxw)

In Google sheet, add original NA value to numeric ranges where NA was replaced 
(e.g. "36-69, missing")

```{r}
write_csv(teamds_dict, here::here("output", "teamds_dict.csv"))
```


Get "long" version for ETL sheet

```{r}
teamds_conditions_long <- teamds_clinical_data_converted %>% 
  select(where(is.character)) %>% 
  pivot_longer(cols = everything(),
               names_to = "original_header",
               values_to = "all_values") %>% 
  group_by(original_header) %>% 
  summarize(unique_values = unique(all_values)) %>% 
  arrange(unique_values, .by_group = TRUE) %>%
  ungroup() %>% 
  filter(unique_values != "missing" & unique_values != "No")
```

```{r}
write_csv(teamds_conditions_long, 
          here::here("output", "teamds_conditions_long.csv"))
```


## HARMONIZE PARTICIPANT

Checks

```{r}
# N unique participants
length(unique(teamds_clinical_data_converted$studyid)) #122

# duplicate ids?
teamds_clinical_data_converted %>% janitor::get_dupes(studyid) #0


```
